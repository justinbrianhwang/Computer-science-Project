# Natural Language Processing Bible

## Introduction

This directory contains organized notes and materials summarizing the book **"Natural Language Processing Bible"** by **Im Hee-seok**. The purpose of this project is to provide a helpful resource for students to study natural language processing (NLP) more efficiently and effectively.

## Table of Contents

### **PART I: Core Theories of Natural Language Processing**

#### **CHAPTER 1: Basics of Natural Language Processing**
1.1 What is Natural Language Processing? 
1.2 Application Areas of Natural Language Processing 
1.3 Why is Natural Language Processing Difficult? 
1.4 Paradigms in Natural Language Processing Research 
1.5 Natural Language Processing with Deep Learning 
References 

#### **CHAPTER 2: Mathematics for Natural Language Processing**
2.1 Basics of Probability 
2.2 MLE and MAP 
2.3 Information Theory and Entropy 
References 

#### **CHAPTER 3: Basic Principles of Linguistics**
3.1 Overview of Linguistics 
3.2 Syllables, Morphemes, Words, and Parts of Speech 
3.3 Phrase Structure and Dependency Structure 
3.4 Semantics and Pragmatics 
References 

#### **CHAPTER 4: Text Preprocessing**
4.1 Errors in Unstructured Data 
4.2 Transforming Text Documents 
4.3 Methods for Correcting Spacing 
4.4 Methods for Spelling and Grammar Correction 
References 

#### **CHAPTER 5: Lexical Analysis**
5.1 Morphological Analysis 
5.2 Part-of-Speech Tagging 
5.3 Applications of Morphological Analysis and Part-of-Speech Tagging 
References 

#### **CHAPTER 6: Syntactic Parsing**
6.1 Overview of Syntactic Parsing 
6.2 Phrase Structure Parsing 
6.3 Dependency Parsing 
6.4 Pros and Cons of Parsing Approaches 
6.5 Further Reading 
References 

#### **CHAPTER 7: Semantic Analysis**
7.1 Word and Word Sense Disambiguation 
7.2 Methods for Word Sense Disambiguation 
7.3 Semantic Role Analysis 
7.4 Semantic Representation 
References 

### **PART II: Applied Systems in Natural Language Processing**

#### **CHAPTER 8: Named Entity Recognition (NER)**
8.1 Introduction to Named Entity Recognition 
8.2 What is Named Entity Recognition? 
8.3 NER Systems 
8.4 NER Evaluation Metrics 
8.5 BIO Tagging Scheme 
8.6 Training Corpora 
References 

#### **CHAPTER 9: Language Models**
9.1 What is a Language Model? 
9.2 Statistical Language Models 
9.3 Generalization 
9.4 Model Evaluation and Perplexity 
References 

#### **CHAPTER 10: Information Extraction**
10.1 What is Information Extraction? 
10.2 Learning Methods for Information Extraction 
10.3 Relation Extraction 
10.4 Approaches to Information Extraction (Relation Extraction) 
References 

#### **CHAPTER 11: Question & Answering**
11.1 What is Question & Answering? 
11.2 Information Retrieval-Based Question & Answering 
References 

#### **CHAPTER 12: Machine Translation**
12.1 What is Machine Translation? 
12.2 Rule-Based Machine Translation 
12.3 Statistical Machine Translation 
12.4 Phrase-Based Translation 
12.5 Practical Sentence Translation Using Statistical Models 
References 

#### **CHAPTER 13: Natural Language Generation**
13.1 Background 
13.2 Supervised Learning-Based Natural Language Generation 
13.3 Reinforcement Learning-Based Natural Language Generation 
13.4 Adversarial Learning-Based Natural Language Generation 
References 

#### **CHAPTER 14: Dialogue Systems**
14.1 Introduction to Dialogue Systems 
14.2 Classification of Dialogue Systems 
References 

#### **CHAPTER 15: Text Summarization**
15.1 What is Text Summarization? 
15.2 Methods for Text Summarization 
15.3 Approaches 
15.4 Evaluation 
References 

#### **CHAPTER 16: Text Categorization**
16.1 What is Text Categorization? 
16.2 Everyday Text Categorization 
16.3 What is Sentiment Analysis? 
16.4 Various Examples of Text Categorization 
16.5 Text Categorization Process 
16.6 Text Categorization and Clustering Algorithms 
16.7 Scikit-Learn 
16.8 Data Visualization 
References 

### **PART III: Deep Learning-Based Natural Language Processing**

#### **CHAPTER 17: Introduction to Deep Learning**
17.1 Overview of Deep Learning 
17.2 Core of Deep Learning Models: Automatic Hierarchical Feature Representation Learning 
17.3 Considerations for Building Deep Learning Systems: Data and Model Structure 
17.4 Backbone of Deep Learning Models: Perceptron 
17.5 Non-Linear Decision Boundaries and Activation Functions 
17.6 Training Deep Learning Models 
References 

#### **CHAPTER 18: Word Embedding**
18.1 What is Word Embedding? 
18.2 Distributional Hypothesis and Language Modeling 
18.3 Word Embedding Before Word2vec 
18.4 Word Embedding from Word2vec to ELMo 
18.5 Sentence-Level Embedding After ELMo 
18.6 Korean Word Embedding and Minimum Unit of Input 
18.7 Latest Research Trends 
References 

#### **CHAPTER 19: Convolutional Neural Networks (CNN)**
19.1 Concept of CNN 
19.2 Sentence Classification Using CNN 
References 

#### **CHAPTER 20: Recurrent Neural Networks (RNN)**
20.1 Basic Recurrent Neural Networks 
20.2 Advanced Recurrent Neural Networks 
20.3 Natural Language Generation Using Recurrent Neural Networks 
References 

#### **CHAPTER 21: Deep Learning-Based Korean Morphological Analysis and Part-of-Speech Tagging**
21.1 Overview of Morphological Analysis and Part-of-Speech Tagging 
21.2 Introduction to KoNLPy Morphological Analysis Tools 
21.3 Morphological Analysis and Part-of-Speech Tagging Before Deep Learning 
21.4 Deep Learning-Based Morphological Analysis and Part-of-Speech Tagging 
References 

#### **CHAPTER 22: Deep Learning-Based Korean Word Sense Analysis**
22.1 Korean Semantic Role Analysis 
22.2 Deep Learning-Based Word Sense Disambiguation 
References 

#### **CHAPTER 23: Deep Learning-Based Named Entity Recognition (NER)**
23.1 Deep Learning-Based NER 
23.2 Word-Level Structure 
23.3 Character-Level Structure 
23.4 Word+Character-Level Structure 
References 

#### **CHAPTER 24: Deep Learning-Based Question & Answering**
24.1 Deep Learning-Based Question & Answering 
24.2 Deep Learning-Based Question & Answering Models 
24.3 Visual Question Answering (VQA) 
References 

#### **CHAPTER 25: Deep Learning-Based Machine Translation**
25.1 Introduction and Trends in Machine Translation 
25.2 Trends in Deep Learning-Based Machine Translation 
25.3 Sequence to Sequence Structure and Encoder-Decoder 
25.4 RNN-Based Neural Machine Translation 
25.5 Emergence of Attention 
25.6 Transformer 
25.7 Self-Attention 
25.8 Multi-Head Attention 
25.9 Positional Encoding 
25.10 Residual & Layer Normalization 
25.11 Decoder 
25.12 Linear Layer & Softmax 
References 

#### **CHAPTER 26: Deep Learning-Based Sentence Generation**
26.1 Sentence Generation Using Recurrent Neural Network Language Models 
26.2 Sentence Generation Using Self-Attention Language Models 
References 

#### **CHAPTER 27: Deep Learning-Based Text Summarization**
27.1 Trends in Deep Learning-Based Text Summarization 
27.2 Deep Learning-Based Abstractive Summarization 
References 

#### **CHAPTER 28: Deep Learning-Based Dialogue Systems**
28.1 Task-Oriented Dialogue Systems 
28.2 Non-Task-Oriented Dialogue Systems (Chatbot Systems) 
References 

#### **CHAPTER 29: Deep Learning for Social Network Service (SNS) Analysis**
29.1 Social Network Services 
29.2 SNS Analysis 
29.3 SNS Analysis Techniques 
References 

#### **CHAPTER 30: Application: Image Caption Generation**
30.1 Overview of Image Caption Generation 
30.2 Process of Image Caption Generation 
30.3 Image Caption Generation Model: Show & Tell 
30.4 Performance Changes with Training 
References 

## Purpose

The main objective of creating this directory is to aid students in their studies by providing a structured and accessible resource. We hope that by organizing these materials, more students will find it easier to understand and apply the concepts of natural language processing in various fields such as computer science, engineering, and more.

---

Thank you for using this resource. We hope it proves to be a valuable aid in your studies. If you have any suggestions or contributions, please feel free to make a pull request or contact us.


